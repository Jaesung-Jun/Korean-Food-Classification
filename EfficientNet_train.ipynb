{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95d689e4",
   "metadata": {},
   "source": [
    "# 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input, EfficientNetB0\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "\n",
    "from osAdvanced import File_Control\n",
    "from ProgressBar import Progress_Bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29b906",
   "metadata": {},
   "source": [
    "# 2. Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d345e5f",
   "metadata": {},
   "source": [
    "## 2.1 데이터 경로를 불러온 뒤 label 정보를 dictionary 형태로 저장하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4965f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = File_Control.searchAllFilesInDirectoryByDir(\"/raid/korean_food/\", \"jpg\")\n",
    "label_dict = {}\n",
    "p = re.compile(\"\\/[가-힣]*\\/.*\\/\")\n",
    "for i in range(len(dataset)):\n",
    "    label = p.search(dataset[i][0]).group()\n",
    "    label = label.replace(\"/\", \"|\")\n",
    "    label_dict[str(i)] = label[1:len(label)-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eadebd",
   "metadata": {},
   "source": [
    "## 2.3 데이터 전처리\n",
    "나중에 전처리 과정을 생략 가능하게끔 Pickle형태로 전처리된 데이터를 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementCount(list):\n",
    "    count = 0\n",
    "    for element in list:\n",
    "        count += len(element)\n",
    "    return count\n",
    "\n",
    "print(\"총 데이터 개수 :\", elementCount(dataset))\n",
    "y = np.ndarray((elementCount(dataset)), dtype=np.int32)\n",
    "x = np.ndarray((elementCount(dataset), 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "dataset_len = elementCount(dataset)\n",
    "index = 0\n",
    "RESIZE_WIDTH = 224\n",
    "RESIZE_HEIGHT = 224\n",
    "CHANNEL = 3\n",
    "for i in range(len(dataset)):\n",
    "    for data in dataset[i]:\n",
    "        img = Image.open(data)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize((RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "        img = preprocess_input(np.array(img))\n",
    "        y[index] = i\n",
    "        x[index] = img\n",
    "        index = index + 1\n",
    "        Progress_Bar.printProgressBar(index, dataset_len, data)\n",
    "\n",
    "y_unique_num = np.unique(y, axis=0)\n",
    "y_unique_num = y_unique_num.shape[0]\n",
    "\n",
    "y_encoded = np.eye(y_unique_num)[y] # One-Hot Encoding\n",
    "\n",
    "pickle_list = [x, y_encoded]\n",
    "with open('/raid/korean_food_pkl/preprocessed_data_0530_EfficientNet.pkl', 'wb') as f:\n",
    "    pickle.dump(pickle_list, f)\n",
    "print(\"pickle saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b126e27",
   "metadata": {},
   "source": [
    "## 2.4 전처리된 Pickle 데이터 불러오기.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4331244",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/korean_food_pkl/preprocessed_data_0530_EfficientNet.pkl\", 'rb') as f:\n",
    "    data = pickle.load(f) # 단 한줄씩 읽어옴\n",
    "\n",
    "x = data[0]\n",
    "y = data[1]\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0449bcf",
   "metadata": {},
   "source": [
    "## 2.5 불러온 데이터를 Train/Test/Validation Set으로 나누기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fdb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valtest, y_train, y_valtest = train_test_split(x, y, test_size = 0.3, random_state=1)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_valtest, y_valtest, test_size = 0.5, random_state=1)\n",
    "\n",
    "del x\n",
    "del y\n",
    "del x_valtest\n",
    "del y_valtest\n",
    "\n",
    "print(\"train size : \", y_train.shape[0])\n",
    "print(\"test size : \", y_test.shape[0])\n",
    "print(\"validation size : \", y_val.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9856c3a1",
   "metadata": {},
   "source": [
    "## 2.5 데이터 로드가 잘 되었는지 확인\n",
    "matplot에서는 한글 지원이 안되므로 폰트 파일을 불러와 추가함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb363d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "\"\"\"\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_name = mpl.font_manager.FontProperties(fname=path).get_name()\n",
    "plt.rc('font', family=font_name)\n",
    "print([f.fname for f in matplotlib.font_manager.fontManager.ttflist])\n",
    "\"\"\"\n",
    "\n",
    "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "prop = fm.FontProperties(fname=path, size=18)\n",
    "\n",
    "w = 10\n",
    "h = 10\n",
    "columns = 4\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = []\n",
    "for i in range(columns*rows):\n",
    "    img_index = random.randint(0, len(y_train))\n",
    "    img = x_train[img_index]\n",
    "    #img = img[:,:,::-1]\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "    y_str = str(np.argmax(y_train[img_index]))\n",
    "    ax[-1].set_title(label_dict[y_str], fontproperties=prop)  # set title\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c240ee7",
   "metadata": {},
   "source": [
    "# 3. 모델 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6227ca",
   "metadata": {},
   "source": [
    "## 3.1 EfficientNetB0모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687de08",
   "metadata": {},
   "outputs": [],
   "source": [
    " def fc_layers(model):\n",
    "    x = model.output\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(1024, name=\"dense_1\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(512, name=\"dense_2\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    x = layers.Dense(150, activation='softmax', name='dense_3')(x)\n",
    "    model = keras.Model(model.input, x)\n",
    "    return model\n",
    "\n",
    "print(\"train shape : \", x_train.shape)\n",
    "print(\"test shape : \", x_test.shape)\n",
    "print(\"validation shape : \", x_val.shape)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "IMAGE_SHAPE = (224, 224, 3)\n",
    "\n",
    "model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    weights=None,\n",
    "    classes=150,\n",
    ")\n",
    "\n",
    "model = fc_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ce79c",
   "metadata": {},
   "source": [
    "## 3.1 모델 컴파일 및 하이퍼 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e51b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "prediction_layer = tf.keras.layers.Dense(150)\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = resnet_101_model(x)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "resnet_101_model = tf.keras.Model(inputs, outputs)\n",
    "\"\"\"\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f142f3",
   "metadata": {},
   "source": [
    "## 3.2 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b816d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CHECKPOINT_PATH = './checkpoints_0530_efficientNet'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=CHECKPOINT_PATH,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "model_early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "#early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "\n",
    "hist = model.fit(x_train,\n",
    "                 y_train,\n",
    "                 epochs = 50,\n",
    "                 batch_size = 32,\n",
    "                 validation_data=(x_val, y_val), \n",
    "                 callbacks=[model_checkpoint_callback, model_early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4841c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = model.evaluate(x_test, y_test)\n",
    "print(eval_result)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "968d1d27de8c6fe2d9b4c246f0b159baa402f868f7088fc351d8af9a36abb023"
  },
  "kernelspec": {
   "display_name": "tf-2.7.0",
   "language": "python",
   "name": "tf-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
